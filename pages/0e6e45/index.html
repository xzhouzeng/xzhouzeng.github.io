<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Graph Transformers | XZ Blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="Learning notes and sharing">
    <meta name="keywords" content="后端开发,技术文档,论文解读,AI,个人博客,markdown">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.b7b742a8.css" as="style"><link rel="preload" href="/assets/js/app.18e93aeb.js" as="script"><link rel="preload" href="/assets/js/4.5da4c663.js" as="script"><link rel="preload" href="/assets/js/14.4e11c2f1.js" as="script"><link rel="prefetch" href="/assets/js/10.992967a5.js"><link rel="prefetch" href="/assets/js/11.c52b3af9.js"><link rel="prefetch" href="/assets/js/12.8b14894a.js"><link rel="prefetch" href="/assets/js/13.248068ad.js"><link rel="prefetch" href="/assets/js/15.d3fe0767.js"><link rel="prefetch" href="/assets/js/16.a996b679.js"><link rel="prefetch" href="/assets/js/17.b929c3be.js"><link rel="prefetch" href="/assets/js/18.1b3cba78.js"><link rel="prefetch" href="/assets/js/19.d43a7649.js"><link rel="prefetch" href="/assets/js/2.b9c1d12c.js"><link rel="prefetch" href="/assets/js/20.3e49278f.js"><link rel="prefetch" href="/assets/js/21.9f4fbcc5.js"><link rel="prefetch" href="/assets/js/22.5cef0557.js"><link rel="prefetch" href="/assets/js/23.c01a93e7.js"><link rel="prefetch" href="/assets/js/24.5eac4a25.js"><link rel="prefetch" href="/assets/js/25.0f4d68da.js"><link rel="prefetch" href="/assets/js/26.150c30d8.js"><link rel="prefetch" href="/assets/js/27.99d9bb0b.js"><link rel="prefetch" href="/assets/js/28.1750d92d.js"><link rel="prefetch" href="/assets/js/29.f03e7b1f.js"><link rel="prefetch" href="/assets/js/3.4e8b7ea8.js"><link rel="prefetch" href="/assets/js/30.b6370dc7.js"><link rel="prefetch" href="/assets/js/31.2328bcc3.js"><link rel="prefetch" href="/assets/js/32.893286dc.js"><link rel="prefetch" href="/assets/js/33.22e4b8b4.js"><link rel="prefetch" href="/assets/js/34.94363ed6.js"><link rel="prefetch" href="/assets/js/35.e911a9b9.js"><link rel="prefetch" href="/assets/js/36.78922f50.js"><link rel="prefetch" href="/assets/js/37.c0e66f90.js"><link rel="prefetch" href="/assets/js/38.9ac493ff.js"><link rel="prefetch" href="/assets/js/39.421d1a3d.js"><link rel="prefetch" href="/assets/js/40.51f444ee.js"><link rel="prefetch" href="/assets/js/41.dcd6f548.js"><link rel="prefetch" href="/assets/js/42.3902dae8.js"><link rel="prefetch" href="/assets/js/43.6b5576f1.js"><link rel="prefetch" href="/assets/js/44.1b50b2da.js"><link rel="prefetch" href="/assets/js/45.91ea8924.js"><link rel="prefetch" href="/assets/js/46.57a2a446.js"><link rel="prefetch" href="/assets/js/47.367db1d8.js"><link rel="prefetch" href="/assets/js/48.c75d5943.js"><link rel="prefetch" href="/assets/js/49.53d35fc2.js"><link rel="prefetch" href="/assets/js/5.61ecad96.js"><link rel="prefetch" href="/assets/js/6.998dbaa8.js"><link rel="prefetch" href="/assets/js/7.5d8352cc.js"><link rel="prefetch" href="/assets/js/8.21fcb95f.js"><link rel="prefetch" href="/assets/js/9.7b6e03ff.js">
    <link rel="stylesheet" href="/assets/css/0.styles.b7b742a8.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/logo.png" alt="XZ Blog" class="logo"> <span class="site-name can-hide">XZ Blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="文档" class="dropdown-title"><a href="/doc/" class="link-title">文档</a> <span class="title" style="display:none;">文档</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/b406c0/" class="nav-link">人体姿态估计</a></li><li class="dropdown-item"><!----> <a href="/pages/1186a5/" class="nav-link">2D-3D-Lifting</a></li><li class="dropdown-item"><!----> <a href="/pages/f0fb64/" class="nav-link">动作质量评估</a></li><li class="dropdown-item"><!----> <a href="/pages/1aa734/" class="nav-link">基于RGBD视觉信息的异常行为识别</a></li><li class="dropdown-item"><!----> <a href="/pages/ce88a1/" class="nav-link">基于RGB视频的行为识别</a></li><li class="dropdown-item"><!----> <a href="/pages/0dsfd5/" class="nav-link">大模型应用</a></li><li class="dropdown-item"><h4>网络结构</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/xxx/" class="nav-link">Transformer</a></li><li class="dropdown-subitem"><a href="/pages/xxx/" class="nav-link">GCN</a></li><li class="dropdown-subitem"><a href="/pages/0e6e45/" aria-current="page" class="nav-link router-link-exact-active router-link-active">Graph Transformers</a></li><li class="dropdown-subitem"><a href="/pages/413fa2/" class="nav-link">Diffusion Model</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法" class="dropdown-title"><a href="/ai/" class="link-title">算法</a> <span class="title" style="display:none;">算法</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/e4e08c/" class="nav-link">深度学习</a></li><li class="dropdown-item"><!----> <a href="/pages/61f973/" class="nav-link">论文解读</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/t6068a3/" class="nav-link">后端开发</a></li><li class="dropdown-item"><!----> <a href="/pages/1fa324/" class="nav-link">Git</a></li><li class="dropdown-item"><!----> <a href="/pages/bed179/" class="nav-link">博客搭建</a></li><li class="dropdown-item"><!----> <a href="/pages/f56caf/" class="nav-link">Debug</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/1db558/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/434772/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/5c4f4b/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/xzhouzeng/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/img/head.jpg"> <div class="blogger-info"><h3>xzhouzeng</h3> <span>@渐行。</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="文档" class="dropdown-title"><a href="/doc/" class="link-title">文档</a> <span class="title" style="display:none;">文档</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/b406c0/" class="nav-link">人体姿态估计</a></li><li class="dropdown-item"><!----> <a href="/pages/1186a5/" class="nav-link">2D-3D-Lifting</a></li><li class="dropdown-item"><!----> <a href="/pages/f0fb64/" class="nav-link">动作质量评估</a></li><li class="dropdown-item"><!----> <a href="/pages/1aa734/" class="nav-link">基于RGBD视觉信息的异常行为识别</a></li><li class="dropdown-item"><!----> <a href="/pages/ce88a1/" class="nav-link">基于RGB视频的行为识别</a></li><li class="dropdown-item"><!----> <a href="/pages/0dsfd5/" class="nav-link">大模型应用</a></li><li class="dropdown-item"><h4>网络结构</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/xxx/" class="nav-link">Transformer</a></li><li class="dropdown-subitem"><a href="/pages/xxx/" class="nav-link">GCN</a></li><li class="dropdown-subitem"><a href="/pages/0e6e45/" aria-current="page" class="nav-link router-link-exact-active router-link-active">Graph Transformers</a></li><li class="dropdown-subitem"><a href="/pages/413fa2/" class="nav-link">Diffusion Model</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="算法" class="dropdown-title"><a href="/ai/" class="link-title">算法</a> <span class="title" style="display:none;">算法</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/e4e08c/" class="nav-link">深度学习</a></li><li class="dropdown-item"><!----> <a href="/pages/61f973/" class="nav-link">论文解读</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/t6068a3/" class="nav-link">后端开发</a></li><li class="dropdown-item"><!----> <a href="/pages/1fa324/" class="nav-link">Git</a></li><li class="dropdown-item"><!----> <a href="/pages/bed179/" class="nav-link">博客搭建</a></li><li class="dropdown-item"><!----> <a href="/pages/f56caf/" class="nav-link">Debug</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/1db558/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/434772/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/5c4f4b/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/xzhouzeng/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>人体姿态估计</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>动作质量评估</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>基于骨骼的行为识别</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>基于RGB视频的行为识别</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>大模型应用</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>网络架构</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>Graph Transformer</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/0e6e45/" aria-current="page" class="active sidebar-link">Graph Transformers</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/pages/0e6e45/#介绍" class="sidebar-link">介绍</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#综述" class="sidebar-link">综述</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/0e6e45/#文献" class="sidebar-link">文献</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#gtns-2019-neurips" class="sidebar-link">GTNs（2019 NeurIPS）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#gtos-2020-aaai" class="sidebar-link">GTOS（2020 AAAI）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#gt-2021-aaai-workshop" class="sidebar-link">GT（2021 AAAI Workshop）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#graphtrans-2021-neurips" class="sidebar-link">GraphTrans（2021 NeurIPS）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#san-2021-neurips" class="sidebar-link">SAN（2021 NeurIPS）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#graphormer-2021-neurips" class="sidebar-link">Graphormer（2021 NeurIPS）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#sat-2022-icml" class="sidebar-link">SAT（2022 ICML）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#graphgps-2022-neurips" class="sidebar-link">GraphGPS（2022 NeurIPS）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#grpe-2022-iclr-oral" class="sidebar-link">GRPE（2022 ICLR Oral）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#nodeformer-2022-neurips" class="sidebar-link">NodeFormer （2022 NeurIPS）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#tokengt-2022-neurips" class="sidebar-link">TokenGT（2022 NeurIPS）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#egt-2022-kdd" class="sidebar-link">EGT（2022 KDD）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#ans-gt-2022-neurips" class="sidebar-link">ANS-GT（2022 NeurIPS）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#matformer-2022-neurips" class="sidebar-link">Matformer（2022 NeurIPS）</a></li><li class="sidebar-sub-header level3"><a href="/pages/0e6e45/#relational-attention-2023-iclr" class="sidebar-link">Relational Attention（2023 ICLR）</a></li></ul></li></ul></li></ul></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>DiffusionModel</span> <span class="arrow right"></span></p> <!----></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>视频生成</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>NLP</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/doc/#文档" data-v-06225672>文档</a></li><li data-v-06225672><a href="/doc/#网络架构" data-v-06225672>网络架构</a></li><li data-v-06225672><a href="/doc/#Graph Transformer" data-v-06225672>Graph Transformer</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/xzhouzeng" target="_blank" title="作者" class="beLink" data-v-06225672>xzhouzeng</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-05-24</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">Graph Transformers<!----></h1> <!----> <div class="theme-vdoing-content content__default"><h1 id="graph-transformers"><a href="#graph-transformers" class="header-anchor">#</a> Graph Transformers</h1> <h2 id="介绍"><a href="#介绍" class="header-anchor">#</a> 介绍</h2> <p>GCN与Transformer的融合</p> <p>没有位置编码层的 Transformer 是置换不变的，并且 Transformer 还具有良好的可扩展性，因此研究人员在近期开始考虑将 Transformers 应用于图中。大多数方法的重点是通过寻找最佳特征和最佳方式来表示图形，并改变注意力以适应这种新数据。</p> <p>将 Transformer 用于图在很大程度上仍处于起步阶段，但就目前来看，其前景也十分可观，它可以缓解 GNN 的一些限制，例如缩放到更大或更密集的图，或是在不过度平滑的情况下增加模型大小。</p> <p>图上不同的 transformers 的主要区别在于（1）如何设计 PE，（2）如何利用结构信息（结合 GNN 或者利用结构信息去修正 attention score, etc）。</p> <p>参考资料：</p> <p><a href="https://zhuanlan.zhihu.com/p/536489997" target="_blank" rel="noopener noreferrer">一文带你浏览Graph Transformers - 知乎 (zhihu.com)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><a href="https://www.leiphone.com/category/academic/lLphrsXP2WtFU9Q1.html" target="_blank" rel="noopener noreferrer">图机器学习无处不在，用 Transformer 可缓解 GNN 限制 | 雷峰网 (leiphone.com)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><a href="https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/125687966" target="_blank" rel="noopener noreferrer">一文带你浏览Graph Transformers_PaperWeekly的博客-CSDN博客<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h3 id="综述"><a href="#综述" class="header-anchor">#</a> 综述</h3> <blockquote><p>Transformer for Graphs: An Overview from Architecture Perspective</p> <p>A Bird’s-Eye Tutorial of Graph Attention Architectures</p></blockquote> <h2 id="文献"><a href="#文献" class="header-anchor">#</a> 文献</h2> <h3 id="gtns-2019-neurips"><a href="#gtns-2019-neurips" class="header-anchor">#</a> GTNs（2019 NeurIPS）</h3> <blockquote><p>Graph Transformer Networks</p></blockquote> <p>用于学习异构图上的节点表示，方法是将异构图转换为由元路径定义的多个新图，这些元图具有任意边类型和任意长度，通过在学习的元路径图上进行卷积来表示节点。</p> <p>（非Transformer）</p> <h3 id="gtos-2020-aaai"><a href="#gtos-2020-aaai" class="header-anchor">#</a> GTOS（2020 AAAI）</h3> <blockquote><p>Graph Transformer for Graph-to-Sequence Learning</p></blockquote> <p><a href="https://blog.csdn.net/qq_36426650/article/details/110832378" target="_blank" rel="noopener noreferrer">论文解读：Graph Transformer for Graph-to-Sequence Learning_华师数据学院·王嘉宁的博客-CSDN博客_graph transformer<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><strong>动机：</strong>
先前 的GNN的缺陷：
（1）固有的局部传播更新自然而然地排除了一些有效的全局交互，不利于大规模的图或当两个结点距离很远的情况;</p> <p>假设对一个图结构进行训练，迭代次数设置为L，因此对于每个结点其只能有机会与其在L
跳数之内的所有结点实现直接的信息交互，而超过范围的结点之间信息得不到显式的交互。这类似于在RNN及其相关变体中存在的梯度消失问题。</p> <p>（2）尽管两个结点能够在一定距离范围内可达，而由于过长距离信息也会被削弱；</p> <p>当然第一种情况可以避免，例如增加迭代次数，另外即便在一定跳数范围内信息得不到直接交互，但通过中间部分结点也可以实现简介的信息交互，但可想而知过长的距离使得这些信息变得非常的稀疏；</p> <p>（3）Transformer：完全以Attention实现对不同成分之间的进行显式的信息交互，不受到长距离的限制。但现有的Transformer模型均只在序列模型上得以验证，而并没有在图结构上进行应用。</p> <p>Transformer的思想是将每个结点抽象为一个全连接图，每个结点均可以与所有结点进行信息交互，但它们的交互并没有融入实际的结点与结点见的关系relation，特别是对于像依存句法树（Dependency Tree，DP）和抽象语义表示（Abstract Mean Representation，AMR）等富含边信息。因此需要模型能够显式地学习这些边的信息的同时，不受到距离约束的影响。</p> <p><strong>本文提出一种Graph Transformer模型，主要解决两个问题：</strong>
（1）先期GNN及其变种模型中没有解决的结点之间长距离信息交互问题，我们将输入的图抽象为一个全连接图，因此可以借助Transformer的特性来实现；因此每个结点都可以获得其他所有结点的信息，不会受到距离限制；
（2）先前图表征模型并没有对关系边信息进行表示，部分方法将边视为一个结点，但这依然不能全面的提取图的全局信息，因此我们需要引入对关系的表征来避免信息的稀疏性；由于有些结点之间并不是单跳内可达，因此为了能够表示任意两个结点之间的关系，使用最短路径来表示，因此引用GRU来实现关系的表征。
<img src="/assets/img/2023-02-02-22-44-17-image.6f581d28.png" title="" alt="" data-align="center"></p> <p><strong>总结：</strong>
  本文提出一种图表示方法，旨在解决先前的GNN-based方法只考虑到单跳（one-hop/first-order）范围内的结点的信息聚集，而忽略对长距离的结点信息交互的问题，提出的Graph Transformer方法则可以实现每个结点之间进行显式地信息交互，并<strong>将结点之间的最短路径关系表征作为保留图结构信息的依据。</strong>
  缺点则在于不适用于大规模的图训练，因为Transformer之所以速度快是因为使用可并行处理的attention，而本文将关系路径使用GRU进行编码，直接破坏了attention带来的优势，使得计算量进一步增加。</p> <h3 id="gt-2021-aaai-workshop"><a href="#gt-2021-aaai-workshop" class="header-anchor">#</a> GT（2021 AAAI Workshop）</h3> <blockquote><p>A Generalization of Transformer Networks to Graphs</p></blockquote> <p><a href="https://zhuanlan.zhihu.com/p/365129455" target="_blank" rel="noopener noreferrer">Graph Transformer——合理灌水 - 知乎 (zhihu.com)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><a href="https://zhuanlan.zhihu.com/p/542486769" target="_blank" rel="noopener noreferrer">Laplacian PE - 知乎 (zhihu.com)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>graph_transformer_edge_layer介绍详细参考代码：<a href="https://github.com/graphdeeplearning/graphtransformer/blob/main/layers/graph_transformer_edge_layer.py" target="_blank" rel="noopener noreferrer">graphtransformer/graph_transformer_edge_layer.py at main · graphdeeplearning/graphtransformer (github.com)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>作者提出了一种适用于任意图的transformer神经网络结构的推广方法。原始的transformer是建立在全连接的图上，这种结构不能很好地利用图的连通归纳偏置——arbitrary and sparsity，即把transformer推广到任意图结构，且表现较弱，<strong>因为图的拓扑结构也很重要，但是没有融合到节点特征中</strong>。
作者提出新的graph transformer，带有以下四个新特征：</p> <ol><li><p>在每个node的可连通临域做attention。</p></li> <li><p>positional encoding用拉普拉斯特征向量表示。</p></li> <li><p>用BN（batch normalization）代替LN（layer normalization），优点：训练更快，泛化性能更好。</p></li> <li><p>将结构扩展到边特征表示.此架构简单而通用，作者相信它可以作为黑盒，应用在transformer和graph的application中。</p></li></ol> <h3 id="graphtrans-2021-neurips"><a href="#graphtrans-2021-neurips" class="header-anchor">#</a> GraphTrans（2021 NeurIPS）</h3> <blockquote><p>Representing Long-Range Context for Graph Neural Networks with Global Attention</p></blockquote> <h3 id="san-2021-neurips"><a href="#san-2021-neurips" class="header-anchor">#</a> SAN（2021 NeurIPS）</h3> <blockquote><p>Rethinking Graph Transformers with Spectral Attention</p></blockquote> <p>近年来，Transformer架构已被证明在序列处理中非常成功，但由于难以正确定义位置，它在其他数据结构（如图形）中的应用仍然有限。在这里，我们提出了光谱注意力网络（SAN），它使用<strong>学习的位置编码（LPE），可以利用全拉普拉斯谱来学习给定图中每个节点的位置</strong>。然后将此LPE添加到图形的节点特征中，并传递给完全连接的Transformer。</p> <p>通过利用拉普拉斯算子的全谱，我们的模型在理论上在区分图方面是强大的，并且可以更好地从它们的共振中检测类似的子结构。此外，通过完全连接图形，Transformer不会遭受过度挤压（大多数GNN的信息瓶颈）的困扰，并能够更好地模拟物理现象，如热传递和电相互作用。</p> <img src="/assets/img/2023-02-04-20-30-48-image.cdedaca0.png" title="" alt="" data-align="center"> <img src="/assets/img/2023-02-04-20-31-28-image.d1428efd.png" title="" alt="" data-align="center"> <h3 id="graphormer-2021-neurips"><a href="#graphormer-2021-neurips" class="header-anchor">#</a> Graphormer（2021 NeurIPS）</h3> <blockquote><p>Do Transformers Really Perform Bad for Graph Representation？</p></blockquote> <p><a href="https://www.msra.cn/zh-cn/news/features/ogb-lsc" target="_blank" rel="noopener noreferrer">KDD Cup 2021 | 微软亚洲研究院Graphormer模型荣登OGB-LSC图预测赛道榜首 (msra.cn)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h3 id="sat-2022-icml"><a href="#sat-2022-icml" class="header-anchor">#</a> SAT（2022 ICML）</h3> <blockquote><p>Structure-Aware Transformer for Graph Representation Learning</p></blockquote> <h3 id="graphgps-2022-neurips"><a href="#graphgps-2022-neurips" class="header-anchor">#</a> GraphGPS（2022 NeurIPS）</h3> <blockquote><p>Recipe for a General, Powerful, Scalable Graph Transformer</p></blockquote> <h3 id="grpe-2022-iclr-oral"><a href="#grpe-2022-iclr-oral" class="header-anchor">#</a> GRPE（2022 ICLR Oral）</h3> <blockquote><p>GRPE: Relative Positional Encoding for Graph Transformer</p></blockquote> <h3 id="nodeformer-2022-neurips"><a href="#nodeformer-2022-neurips" class="header-anchor">#</a> NodeFormer （2022 NeurIPS）</h3> <blockquote><p>NodeFormer: A Scalable Graph Structure Learning Transformer for Node Classification</p></blockquote> <h3 id="tokengt-2022-neurips"><a href="#tokengt-2022-neurips" class="header-anchor">#</a> TokenGT（2022 NeurIPS）</h3> <blockquote><p>Pure Transformers are Powerful Graph Learners</p></blockquote> <h3 id="egt-2022-kdd"><a href="#egt-2022-kdd" class="header-anchor">#</a> EGT（2022 KDD）</h3> <blockquote><p>Global Self-Attention as a Replacement for Graph Convolution</p></blockquote> <h3 id="ans-gt-2022-neurips"><a href="#ans-gt-2022-neurips" class="header-anchor">#</a> ANS-GT（2022 NeurIPS）</h3> <blockquote><p>Hierarchical Graph Transformer with Adaptive Node Sampling</p></blockquote> <h3 id="matformer-2022-neurips"><a href="#matformer-2022-neurips" class="header-anchor">#</a> Matformer（2022 NeurIPS）</h3> <blockquote><p>Periodic Graph Transformers for Crystal Material Property Prediction</p></blockquote> <h3 id="relational-attention-2023-iclr"><a href="#relational-attention-2023-iclr" class="header-anchor">#</a> Relational Attention（2023 ICLR）</h3> <blockquote><p>Relational Attention: Generalizing Transformers for Graph-Structured Tasks</p></blockquote></div></div> <!----> <div class="page-edit"><div class="edit-link"><a href="https://github.com/xzhouzeng/vuepress-theme-vdoing/edit/master/docs/01.文档/06.网络架构/01.Graph Transformer/01.Graph Transformers.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="tags"><a href="/tags/?tag=Transformer" title="标签">#Transformer</a><a href="/tags/?tag=GCN" title="标签">#GCN</a><a href="/tags/?tag=%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB" title="标签">#论文解读</a></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2023/05/26, 03:03:27</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/b19df9/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">提示工程</div></a> <a href="/pages/413fa2/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">Diffusion Model</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/b19df9/" class="prev">提示工程</a></span> <span class="next"><a href="/pages/413fa2/">Diffusion Model</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/b94dba/"><div>
            音乐和生活都值得热爱
            <!----></div></a> <span class="date">07-13</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/b19df9/"><div>
            提示工程
            <!----></div></a> <span class="date">06-29</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/262d3d/"><div>
            代码生成
            <!----></div></a> <span class="date">06-29</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="xzhouzeng@zju.edu.cn" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/xzhouzeng" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="/pages/b94dba/" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2023
    <span>xzhouzeng | <a href="https://github.com/xzhouzeng/vuepress-theme-vdoing/blob/master/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.18e93aeb.js" defer></script><script src="/assets/js/4.5da4c663.js" defer></script><script src="/assets/js/14.4e11c2f1.js" defer></script>
  </body>
</html>

(window.webpackJsonp=window.webpackJsonp||[]).push([[23],{743:function(e,r,n){"use strict";n.r(r);var a=n(1),o=Object(a.a)({},(function(){var e=this,r=e.$createElement,n=e._self._c||r;return n("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[n("h1",{attrs:{id:"llm-agents"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#llm-agents"}},[e._v("#")]),e._v(" LLM-Agents")]),e._v(" "),n("p",[e._v("Timeline for the first release of related work.")]),e._v(" "),n("img",{attrs:{src:"picture/2023-10-08-11-37-40-image.png",title:"",alt:"","data-align":"center"}}),e._v(" "),n("h2",{attrs:{id:"reasoning"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#reasoning"}},[e._v("#")]),e._v(" Reasoning")]),e._v(" "),n("ol",[n("li",[n("p",[n("strong",[e._v("CoT "),n("code",[e._v("(NIPS-22)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2201.11903",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2201.11903] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("SC-CoT "),n("code",[e._v("(ICLR-23)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2203.11171",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2203.11171] Self-Consistency Improves Chain of Thought Reasoning in Language Models (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Zero-Shot CoT "),n("code",[e._v("(NIPS-22)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2205.11916",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2205.11916] Large Language Models are Zero-Shot Reasoners (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Selection-Inference "),n("code",[e._v("(ICLR-23 top5%)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2205.09712",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2205.09712] Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Least-to-Most "),n("code",[e._v("(ICLR-23)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2205.10625",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2205.10625] Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("MRKL Systems")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2205.00445",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2205.00445] MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Self-Critique")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2206.05802",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2206.05802] Self-critiquing models for assisting human evaluators (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Auto-CoT "),n("code",[e._v("(ICLR-23)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2210.03493",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2210.03493] Automatic Chain of Thought Prompting in Large Language Models (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Self-Refine")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2303.17651",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2303.17651] Self-Refine: Iterative Refinement with Self-Feedback"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Self-Polish")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.14497",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.14497] Self-Polish: Enhance Reasoning in Large Language Models via Problem Refinement"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("ToT "),n("code",[e._v("(NIPS-23 Oral)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.10601",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.10601] Tree of Thoughts: Deliberate Problem Solving with Large Language Models"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("ChatCoT")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.14323",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.14323] ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("RAP")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.14992",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.14992] Reasoning with Language Model is Planning with World Model (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("ReWOO")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.18323",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.18323] ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Thought decomposition")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.00633",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.00633] Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Plan-and-Solve Prompting "),n("code",[e._v("(ACL-23)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.04091",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.04091] Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("SoT")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2307.15337",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2307.15337] Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("SelfCheck")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2308.00436",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2308.00436] SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("GoT")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2308.09687",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2308.09687] Graph of Thoughts: Solving Elaborate Problems with Large Language Models (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("AoT")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2308.10379",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2308.10379] Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("ReConcile")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2309.13007",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2309.13007] ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("LEMA")])]),e._v(" "),n("p",[n("a",{attrs:{href:"http://export.arxiv.org/abs/2310.20689",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2310.20689] Learning From Mistakes Makes LLM Better Reasoner (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Step-Back Prompting")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2310.06117",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2310.06117] Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Analogical Reasoners")])]),e._v(" "),n("p",[n("a",{attrs:{href:"http://export.arxiv.org/abs/2310.01714",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2310.01714] Large Language Models as Analogical Reasoners (arxiv.org)"),n("OutboundLink")],1)])])]),e._v(" "),n("h2",{attrs:{id:"planning"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#planning"}},[e._v("#")]),e._v(" Planning")]),e._v(" "),n("ol",[n("li",[n("p",[n("strong",[e._v("Language Models as Zero-Shot Planners "),n("code",[e._v("(ICML-22)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2201.07207",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2201.07207] Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("SayCan "),n("code",[e._v("(CoRL-22 Oral)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2204.01691",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2204.01691] Do As I Can, Not As I Say: Grounding Language in Robotic Affordances"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Inner Monologue "),n("code",[e._v("(CoRL-22)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2207.05608",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2207.05608] Inner Monologue: Embodied Reasoning through Planning with Language Models"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("ReAct "),n("code",[e._v("(ICLR-23 top5%)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2210.03629",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2210.03629] ReAct: Synergizing Reasoning and Acting in Language Models"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("ICPI "),n("code",[e._v("(NIPS-23)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2210.03821v2",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2210.03821v2] Large Language Models can Implement Policy Iteration"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Re-Prompting"),n("code",[e._v("(NIPS-22 Workshop)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2211.09935",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2211.09935] Planning with Large Language Models via Corrective Re-prompting (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("LLM-Planner "),n("code",[e._v("(ICCV-23)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2212.04088",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2212.04088] LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Don’t Generate, Discriminate"),n("code",[e._v("?�?ACL-23?��")])])]),e._v(" "),n("p",[e._v("https://aclanthology.org/2023.acl-long.270.pdf")])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("DECKARD"),n("code",[e._v("?�?ICML-23?��")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2301.12050",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2301.12050] Do Embodied Agents Dream of Pixelated Sheep: Embodied Decision Making using Language Guided World Modelling (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Describe, Explain, Plan and Select "),n("code",[e._v("(NIPS-23)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2302.01560",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2302.01560] Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Refleion "),n("code",[e._v("(NIPS-23)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2303.11366",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2303.11366] Reflexion: Language Agents with Verbal Reinforcement Learning"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("PaLM-E")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2303.03378",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2303.03378] PaLM-E: An Embodied Multimodal Language Model (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Plan4MC")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2303.16563",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2303.16563] Plan4MC: Skill Reinforcement Learning and Planning for Open-World Minecraft Tasks (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Chat with the Environment")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2303.08268",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2303.08268] Chat with the Environment: Interactive Multimodal Perception Using Large Language Models"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Text2Motion")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2303.12153",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2303.12153] Text2Motion: From Natural Language Instructions to Feasible Plans (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("LLM+P")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2304.11477",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2304.11477] LLM+P: Empowering Large Language Models with Optimal Planning Proficiency"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Self-Debug")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2304.05128",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2304.05128] Teaching Large Language Models to Self-Debug (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("LLM-MCTS "),n("code",[e._v("(NIPS-23)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.14078",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.14078] Large Language Models as Commonsense Knowledge for Large-Scale Task Planning (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("LLMs-World-Models-for-Planning "),n("code",[e._v("(NIPS-23)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.14909",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.14909] Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Voyager")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.16291",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.16291] Voyager: An Open-Ended Embodied Agent with Large Language Models"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("SwiftSage "),n("code",[e._v("(NIPS-23)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.17390",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.17390] SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Plan, Eliminate, and Track")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.02412",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.02412] Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("AdaPlanner")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.16653",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.16653] AdaPlanner: Adaptive Planning from Feedback with Language Models"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Language Models Meet World Models")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.10626",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.10626] Language Models Meet World Models: Embodied Experiences Enhance Language Models (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Ghost in the Minecraft")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.17144",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.17144] Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("AlphaBlock")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2305.18898",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2305.18898] AlphaBlock: Embodied Finetuning for Vision-Language Reasoning in Robot Manipulation (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("RecAgent")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2306.02552",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2306.02552] When Large Language Model based Agent Meets User Behavior Analysis: A Novel User Simulation Paradigm"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Sayplan "),n("code",[e._v("(CoRL-23 Oral)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2307.06135",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2307.06135] SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Robot Task Planning (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Robot-Help "),n("code",[e._v("(CoRL-23 Oral)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2307.01928",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2307.01928] Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("TaPA")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2307.01848",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2307.01848] Embodied Task Planning with Large Language Models (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("A Unified Agent (ICLR-23 Workshop)")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2307.09668",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2307.09668] Towards A Unified Agent with Foundation Models (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("ExpeL")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2308.10144",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2308.10144] ExpeL: LLM Agents Are Experiential Learners"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("TPTU")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2308.03427",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2308.03427] TPTU: Task Planning and Tool Usage of Large Language Model-based AI Agents"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("LLM-DP")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2308.06391",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2308.06391] Dynamic Planning with a LLM (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Retroformer")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2308.02151",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2308.02151] Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("CodePlan")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2309.12499",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2309.12499] CodePlan: Repository-level Coding using LLMs and Planning"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Hierarchical Planning "),n("code",[e._v("(NIPS-23)")])])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2309.08587",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2309.08587] Compositional Foundation Models for Hierarchical Planning"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Agents")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2309.07870",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2309.07870] Agents: An Open-source Framework for Autonomous Language Agents (arxiv.org)"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("Self-driven Grounding")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2309.01352",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2309.01352] Self-driven Grounding: Large Language Model Agents with Automatical Language-aligned Skill Learning"),n("OutboundLink")],1)])]),e._v(" "),n("li",[n("p",[n("strong",[e._v("LATS")])]),e._v(" "),n("p",[n("a",{attrs:{href:"https://arxiv.org/abs/2310.04406",target:"_blank",rel:"noopener noreferrer"}},[e._v("[2310.04406] Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models (arxiv.org)"),n("OutboundLink")],1)])])]),e._v(" "),n("h2",{attrs:{id:"tool"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#tool"}},[e._v("#")]),e._v(" Tool")]),e._v(" "),n("h2",{attrs:{id:"reference-material"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#reference-material"}},[e._v("#")]),e._v(" Reference Material")]),e._v(" "),n("p",[n("a",{attrs:{href:"https://github.com/zjunlp/Prompt4ReasoningPapers",target:"_blank",rel:"noopener noreferrer"}},[e._v('zjunlp/Prompt4ReasoningPapers: Repository for the ACL2023 paper "Reasoning with Language Model Prompting: A Survey". (github.com)'),n("OutboundLink")],1)]),e._v(" "),n("p",[n("a",{attrs:{href:"https://github.com/AGI-Edgerunners/LLM-Planning-Papers",target:"_blank",rel:"noopener noreferrer"}},[e._v("AGI-Edgerunners/LLM-Planning-Papers: Must-read Papers on Large Language Model (LLM) Planning. (github.com)"),n("OutboundLink")],1)])])}),[],!1,null,null,null);r.default=o.exports}}]);
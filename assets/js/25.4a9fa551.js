(window.webpackJsonp=window.webpackJsonp||[]).push([[25],{748:function(t,e,a){"use strict";a.r(e);var s=a(1),o=Object(s.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"视频生成"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#视频生成"}},[t._v("#")]),t._v(" 视频生成")]),t._v(" "),a("p",[t._v("包括视频生成及故事可视化（如漫画等有时间、符合逻辑的连续图片等）")]),t._v(" "),a("h2",{attrs:{id:"背景介绍"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#背景介绍"}},[t._v("#")]),t._v(" 背景介绍")]),t._v(" "),a("h2",{attrs:{id:"相关工作"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#相关工作"}},[t._v("#")]),t._v(" 相关工作")]),t._v(" "),a("h3",{attrs:{id:"vdm-2022-neurips"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#vdm-2022-neurips"}},[t._v("#")]),t._v(" VDM（2022 NeurIPS）")]),t._v(" "),a("blockquote",[a("p",[t._v("Video diffusion models")]),t._v(" "),a("p",[t._v("作者：Google")])]),t._v(" "),a("h3",{attrs:{id:"cogvideo-2023-iclr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#cogvideo-2023-iclr"}},[t._v("#")]),t._v(" Cogvideo（2023 ICLR）")]),t._v(" "),a("blockquote",[a("p",[t._v("Cogvideo: Large-scale pretraining for text-to-video generation via transformers")]),t._v(" "),a("p",[t._v("作者：Tsinghua University")])]),t._v(" "),a("h3",{attrs:{id:"make-a-video-2023-iclr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#make-a-video-2023-iclr"}},[t._v("#")]),t._v(" Make-A-Video（2023 ICLR）")]),t._v(" "),a("blockquote",[a("p",[t._v("Make-A-Video: Text-to-Video Generation without Text-Video Data")]),t._v(" "),a("p",[t._v("作者：Meta AI")])]),t._v(" "),a("h3",{attrs:{id:"imagen-video-2022"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#imagen-video-2022"}},[t._v("#")]),t._v(" Imagen video（2022）")]),t._v(" "),a("blockquote",[a("p",[t._v("Imagen video: High definition video generation with diffusion models")]),t._v(" "),a("p",[t._v("作者：Google")])]),t._v(" "),a("h3",{attrs:{id:"make-a-story-2023-cvpr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#make-a-story-2023-cvpr"}},[t._v("#")]),t._v(" Make-a-story（2023 CVPR）")]),t._v(" "),a("blockquote",[a("p",[t._v("Make-a-story: Visual memory conditioned consistent story generation")])]),t._v(" "),a("h3",{attrs:{id:"ar-ldm-2022"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ar-ldm-2022"}},[t._v("#")]),t._v(" AR-LDM（2022）")]),t._v(" "),a("blockquote",[a("p",[t._v("Synthesizing coherent story with auto-regressive latent diffusion models")])]),t._v(" "),a("h3",{attrs:{id:"visual-storytelling-2016-naacl"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#visual-storytelling-2016-naacl"}},[t._v("#")]),t._v(" Visual Storytelling（2016 NAACL）")]),t._v(" "),a("blockquote",[a("p",[t._v("Visual Storytelling（提出一个数据集）")]),t._v(" "),a("p",[t._v("作者：Microsoft Research")])]),t._v(" "),a("h2",{attrs:{id:"参考资料"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[t._v("#")]),t._v(" 参考资料")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("[showlab/Awesome-Video-Diffusion(https://github.com/showlab/Awesome-Video-Diffusion#video-generation")])]),t._v(" "),a("li")])])}),[],!1,null,null,null);e.default=o.exports}}]);
(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{724:function(a,t,s){a.exports=s.p+"assets/img/2023-07-18-15-09-37-image.87cbe40c.png"},725:function(a,t,s){a.exports=s.p+"assets/img/2023-07-18-15-13-50-image.6c869e98.png"},726:function(a,t,s){a.exports=s.p+"assets/img/2023-07-18-15-16-38-image.cec339cc.png"},727:function(a,t,s){a.exports=s.p+"assets/img/2023-07-18-15-17-50-image.34f44dfc.png"},728:function(a,t,s){a.exports=s.p+"assets/img/2023-07-18-15-19-00-image.ac1f8722.png"},763:function(a,t,s){"use strict";s.r(t);var e=s(1),r=Object(e.a)({},(function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("h1",{attrs:{id:"代码生成"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#代码生成"}},[a._v("#")]),a._v(" 代码生成")]),a._v(" "),e("h2",{attrs:{id:"介绍"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#介绍"}},[a._v("#")]),a._v(" 介绍")]),a._v(" "),e("h2",{attrs:{id:"相关工作"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#相关工作"}},[a._v("#")]),a._v(" 相关工作")]),a._v(" "),e("h3",{attrs:{id:"codex"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#codex"}},[a._v("#")]),a._v(" Codex")]),a._v(" "),e("blockquote",[e("p",[e("a",{attrs:{href:"https://arxiv.org/abs/2107.03374",target:"_blank",rel:"noopener noreferrer"}},[a._v("[2107.03374] Evaluating Large Language Models Trained on Code (arxiv.org)"),e("OutboundLink")],1)]),a._v(" "),e("p",[e("a",{attrs:{href:"https://learn.microsoft.com/zh-cn/azure/cognitive-services/openai/how-to/work-with-code",target:"_blank",rel:"noopener noreferrer"}},[a._v("如何使用 Codex 模型处理代码 - Azure OpenAI Service | Microsoft Learn"),e("OutboundLink")],1)])]),a._v(" "),e("h3",{attrs:{id:"codet5"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#codet5"}},[a._v("#")]),a._v(" CodeT5")]),a._v(" "),e("blockquote",[e("p",[e("a",{attrs:{href:"https://arxiv.org/abs/2109.00859",target:"_blank",rel:"noopener noreferrer"}},[a._v("[2109.00859] CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation (arxiv.org)"),e("OutboundLink")],1)]),a._v(" "),e("p",[a._v("EMNLP 2021")])]),a._v(" "),e("h3",{attrs:{id:"codet5-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#codet5-2"}},[a._v("#")]),a._v(" CodeT5+")]),a._v(" "),e("blockquote",[e("p",[e("a",{attrs:{href:"https://arxiv.org/abs/2305.07922",target:"_blank",rel:"noopener noreferrer"}},[a._v("[2305.07922] CodeT5+: Open Code Large Language Models for Code Understanding and Generation (arxiv.org)"),e("OutboundLink")],1)])]),a._v(" "),e("h3",{attrs:{id:"codegen"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#codegen"}},[a._v("#")]),a._v(" CodeGen")]),a._v(" "),e("blockquote",[e("p",[e("a",{attrs:{href:"https://arxiv.org/abs/2203.13474",target:"_blank",rel:"noopener noreferrer"}},[a._v("[2203.13474] CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis (arxiv.org)"),e("OutboundLink")],1)]),a._v(" "),e("p",[a._v("ICLR 2023")]),a._v(" "),e("p",[a._v("Salesforce Research")])]),a._v(" "),e("h3",{attrs:{id:"codegeex"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#codegeex"}},[a._v("#")]),a._v(" CodeGeeX")]),a._v(" "),e("blockquote",[e("p",[e("a",{attrs:{href:"https://arxiv.org/abs/2303.17568",target:"_blank",rel:"noopener noreferrer"}},[a._v("[2303.17568] CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X (arxiv.org)"),e("OutboundLink")],1)]),a._v(" "),e("p",[a._v("Tsinghua University")])]),a._v(" "),e("h3",{attrs:{id:"starcoder"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#starcoder"}},[a._v("#")]),a._v(" StarCoder")]),a._v(" "),e("blockquote",[e("p",[e("a",{attrs:{href:"https://arxiv.org/abs/2305.06161",target:"_blank",rel:"noopener noreferrer"}},[a._v("[2305.06161] StarCoder: may the source be with you! (arxiv.org)"),e("OutboundLink")],1)]),a._v(" "),e("p",[a._v("BigCode Project")])]),a._v(" "),e("h3",{attrs:{id:"wizardcoder"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#wizardcoder"}},[a._v("#")]),a._v(" WizardCoder")]),a._v(" "),e("blockquote",[e("p",[e("a",{attrs:{href:"https://arxiv.org/abs/2306.08568",target:"_blank",rel:"noopener noreferrer"}},[a._v("[2306.08568] WizardCoder: Empowering Code Large Language Models with Evol-Instruct (arxiv.org)"),e("OutboundLink")],1)])]),a._v(" "),e("h4",{attrs:{id:"出发点"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#出发点"}},[a._v("#")]),a._v(" 出发点")]),a._v(" "),e("p",[a._v("代码大型语言模型（Code-LLM），如StarCoder，在与代码相关的任务中表现出了卓越的性能。然而，"),e("strong",[a._v("大多数现有模型仅在大量原始代码数据上进行预训练，而没有指令微调")]),a._v("。")]),a._v(" "),e("p",[e("strong",[a._v("【相关工作】")])]),a._v(" "),e("p",[a._v("指令调整的引入"),e("strong",[a._v("最初旨在增强LM在不同任务中的泛化能力")]),a._v("。虽然用不同的NLP任务对LM进行微调显示出了有希望的结果，但它往往"),e("strong",[a._v("无法与现实世界用户的意图保持一致")]),a._v("。")]),a._v(" "),e("ol",[e("li",[e("p",[a._v("OpenAI采用了一种不同的方法，"),e("strong",[a._v("邀请人类注释者提供大量人类指令")]),a._v("，包括各种形式和广泛的任务类型。在这个数据集的基础上，OpenAI训练了其GPT3模型，以创建更符合用户输入的InstructGPT。这条发展路线甚至导致了被称为ChatGPT的令人印象深刻的工作。")])]),a._v(" "),e("li",[e("p",[a._v("Alpaca采用了自指令"),e("code",[a._v("（self-instruct）")]),a._v("方法，其中ChatGPT生成指令数据。")])]),a._v(" "),e("li",[e("p",[a._v("Vicuna利用了从ShareGPT.com收集的用户共享对话。")])]),a._v(" "),e("li",[e("p",[a._v("WizardLM引入了Evol instruction方法，该方法涉及对现有指令数据进行进化，以生成更复杂、更多样的数据集。")])])]),a._v(" "),e("p",[e("strong",[a._v("【方法】")])]),a._v(" "),e("p",[a._v("提出了WizardCoder，它通过将Evol instruction方法应用于代码领域，为代码LLM提供了复杂的指令微调功能。")]),a._v(" "),e("p",[e("strong",[a._v("【效果】")])]),a._v(" "),e("p",[a._v("通过对HumanEval、HumanEval+、MBPP和DS1000四个突出的代码生成基准进行全面实验，我们展示了我们模型的卓越功能。它大大超过了所有其他开源代码LLM。此外，在HumanEval和HumanEval+上，我们的模型甚至优于最大的闭源LLM，Anthropic的Claude和谷歌的Bard。")]),a._v(" "),e("h4",{attrs:{id:"详细介绍"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#详细介绍"}},[a._v("#")]),a._v(" 详细介绍")]),a._v(" "),e("ol",[e("li",[e("p",[a._v("应用Evol instruction方法来进化"),e("strong",[a._v("Alpaca使用自我指令生成的代码")])])]),a._v(" "),e("li",[e("p",[a._v("用进化的数据微调预训练的代码LLM "),e("strong",[a._v("StarCoder")]),a._v("。")])])]),a._v(" "),e("h5",{attrs:{id:"evol-instruct-prompts-for-code"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#evol-instruct-prompts-for-code"}},[a._v("#")]),a._v(" Evol-Instruct Prompts for Code")]),a._v(" "),e("p",[a._v("受WizardLM提出的Evol Instruction方法的启发，这项工作还试图使代码指令更加复杂，以增强代码预训练的大型模型的微调效果。为了使Evol指令适应代码领域，我们对进化提示进行了以下修改：")]),a._v(" "),e("ul",[e("li",[e("p",[a._v("通过删除深化、复杂的输入和广度进化，简化进化指令。")])]),a._v(" "),e("li",[e("p",[a._v("通过统一进化提示模板，简化了进化提示的形式。")])]),a._v(" "),e("li",[e("p",[a._v("针对代码域的具体特征，我们添加了两个进化指令：代码调试和代码时空复杂性约束")])])]),a._v(" "),e("p",[a._v("统一的代码进化提示模板如下：")]),a._v(" "),e("div",{staticClass:"language-context line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-context"}},[e("code",[a._v("Please increase the difficulty of the given programming test question a bit. \n\nYou can increase the difficulty using, but not limited to, the following methods: \n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("method"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v(" \n\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("question"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br")])]),e("p",[a._v("这里，{question}表示当前等待进化的代码指令，{method}是进化的类型。我们使用的五种类型如下所示：")]),a._v(" "),e("div",{staticClass:"language-context line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-context"}},[e("code",[a._v("Add new constraints and requirements to the original problem, adding approximately 10 additional words.\n\nReplace a commonly used requirement in the programming task with a less common and more specific one.\n\nIf the original problem can be solved with only a few logical steps, please add more reasoning steps.\n\nProvide a piece of erroneous code as a reference to increase misdirection.\n\nPropose higher time or space complexity requirements, but please refrain from doing so frequently.\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br")])]),e("h5",{attrs:{id:"training-wizardcoder"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#training-wizardcoder"}},[a._v("#")]),a._v(" Training WizardCoder")]),a._v(" "),e("p",[a._v("我们采用以下程序来训练WizardCoder。最初，我们使用"),e("strong",[a._v("StarCoder 15B作为基础")]),a._v("，并使用通过Evol instruction进化而来的代码指令后续训练集对其进行微调。微调的提示格式概述如下：")]),a._v(" "),e("div",{staticClass:"language-context line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-context"}},[e("code",[a._v("Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n###Instruction: "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("instruction"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n###Response:\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br")])]),e("p",[e("strong",[a._v("【总的来说】")])]),a._v(" "),e("p",[a._v("为了构建训练数据集，使用名为Code Alpaca5的20K指令集对其进行了初始化。我们在这个由20000个样本组成的数据集上反复使用Evol Instruction技术来产生进化数据。在每一轮数据进化之后，我们将前几轮的进化数据与原始数据集合并，以微调StarCoder并评估pass@1HumanEval的度量。一旦我们观察到pass@1度量下降，我们将停止使用Evol Instruction，并选择最高的型号pass@1作为终极模型。")]),a._v(" "),e("h4",{attrs:{id:"实验"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#实验"}},[a._v("#")]),a._v(" 实验")]),a._v(" "),e("h5",{attrs:{id:"实现细节"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#实现细节"}},[a._v("#")]),a._v(" 实现细节")]),a._v(" "),e("p",[a._v("StarCoder是基本基础模型。进化数据集由大约78k个样本组成。为了微调基本模型，我们采用了特定的配置，包括512的批量大小、2048的序列长度、200个微调步骤、30个预热步骤、2e-5的学习速率、余弦学习速率调度器和fp16混合精度。")]),a._v(" "),e("h5",{attrs:{id:"evaluation-on-humaneval-humaneval-and-mbpp"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#evaluation-on-humaneval-humaneval-and-mbpp"}},[a._v("#")]),a._v(" Evaluation on HumanEval, HumanEval+, and MBPP")]),a._v(" "),e("p",[a._v("这些任务的提示格式如下：")]),a._v(" "),e("div",{staticClass:"language-context line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-context"}},[e("code",[a._v("Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. \n\n###Instruction: \n\nCreate a Python script for this problem: \n\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("Question"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v(" \n\n###Response:\n\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br"),e("span",{staticClass:"line-number"},[a._v("10")]),e("br")])]),e("p",[e("strong",[a._v("【单次尝试HumanEval（164个问题）的通过率百分比】")])]),a._v(" "),e("p",[a._v("所有基线分数均从LLM Humaneval Benchmarks中检索。我们的WizardCoder通过贪婪解码生成一个答案。")]),a._v(" "),e("img",{attrs:{src:s(724),title:"",alt:"","data-align":"center"}}),a._v(" "),e("p",[e("strong",[a._v("【在HumanEval和MBPP上的pass@1（%）结果】")])]),a._v(" "),e("p",[a._v("大多数分数来自StarCoder和CodeT5+的论文。我们遵循前面的工作（Codex）生成n个样本来估计pass@1使用同一组超参数得分：temperate=0.2，top_p=0.95。*：我们自己评估这个模型。")]),a._v(" "),e("img",{attrs:{title:"",src:s(725),alt:"","data-align":"center",width:"544"}}),a._v(" "),e("p",[a._v("根据实验结果得出以下"),e("mark",[a._v("结论")]),a._v("：")]),a._v(" "),e("ul",[e("li",[e("p",[a._v("WizardCoder的性能优于最大的闭源LLM，包括Claude、Bard、PaLM、PaLM-2和LaMDA，尽管它们明显更小。")])]),a._v(" "),e("li",[e("p",[a._v("WizardCoder的性能大大优于所有开源代码LLM（在HumanEval上为+22.3），包括StarCoder、CodeGen、CodeGee和CodeT5+。")])]),a._v(" "),e("li",[e("p",[a._v("WizardCoder在指令微调方面显著优于所有开源代码LLM，包括InstructionCodeT5+、StarCoder GPTeacher和Instruction-Codegen-16B。")])])]),a._v(" "),e("h5",{attrs:{id:"evaluation-on-ds-1000"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#evaluation-on-ds-1000"}},[a._v("#")]),a._v(" Evaluation on DS-1000")]),a._v(" "),e("p",[a._v("DS-1000上的WizardCoder和基准型号的性能。所有模型都使用相同的超参数集进行评估：温度=0.2，顶部=0.5，最大长度=1024。分数一般pass@1精度超过40个样本。Matplotlib（plt）任务没有正确的上下文，因此插入和完成分数是相同的。")]),a._v(" "),e("img",{attrs:{src:s(726),title:"",alt:"","data-align":"center"}}),a._v(" "),e("h5",{attrs:{id:"消融实验"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#消融实验"}},[a._v("#")]),a._v(" 消融实验")]),a._v(" "),e("p",[a._v("该研究调查了数据进化轮数的影响。第一轮进化数据包含38k个样本。第二轮包含58k。第三轮包含78k。第四轮包含98k。为了保持一致性，所有模型都经过了200步的微调。结果显示pass@1经过三轮数据进化后，获得了人类评估的分数。基于这一观察结果，我们选择第三轮期间演变的数据作为最终数据集。")]),a._v(" "),e("img",{attrs:{title:"",src:s(727),alt:"","data-align":"center",width:"576"}}),a._v(" "),e("h5",{attrs:{id:"示例"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#示例"}},[a._v("#")]),a._v(" 示例")]),a._v(" "),e("p",[a._v("展示了与我们的WizardCoder交互的示例。这些例子表明，我们的模型始终能产生准确的反应，并给出明确的解释。")]),a._v(" "),e("img",{attrs:{title:"",src:s(728),alt:"","data-align":"center",width:"615"}}),a._v(" "),e("h2",{attrs:{id:"实验评估"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#实验评估"}},[a._v("#")]),a._v(" 实验评估")]),a._v(" "),e("h3",{attrs:{id:"数据集"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据集"}},[a._v("#")]),a._v(" 数据集")]),a._v(" "),e("p",[a._v("HumanEval、HumanEval+和MBPP是代码LLM领域中广泛使用的基准测试。这些基准测试包含大量Python编程问题，使用测试用例来验证Code LLM生成的代码。")]),a._v(" "),e("h4",{attrs:{id:"humaneval"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#humaneval"}},[a._v("#")]),a._v(" HumanEval")]),a._v(" "),e("p",[a._v("HumanEval由164个原始编程问题组成，每个问题平均分配9.6个测试用例。")]),a._v(" "),e("h4",{attrs:{id:"humaneval-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#humaneval-2"}},[a._v("#")]),a._v(" HumanEval+")]),a._v(" "),e("p",[a._v("为了确保全面评估LLM合成代码的功能正确性，HumanEval+显著扩展了测试用例的数量，平均每个问题774.8个测试用例。")]),a._v(" "),e("h4",{attrs:{id:"mbpp"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mbpp"}},[a._v("#")]),a._v(" MBPP")]),a._v(" "),e("p",[a._v("MBPP提供了一组500个测试编程问题，每个问题附带三个自动测试用例。")]),a._v(" "),e("h4",{attrs:{id:"ds-1000"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#ds-1000"}},[a._v("#")]),a._v(" DS-1000")]),a._v(" "),e("p",[a._v("DS-1000基准包括跨越七个库的1000个不同的数据科学工作流程。它根据测试用例评估代码生成的性能，并支持两种评估模式：完成和插入。在我们的实验中，我们只报告支持的模型的插入分数。DS-1000基准测试根据所使用的库对问题进行了进一步分类，包括Matplotlib（plt）、NumPy（np）、Pandas（pd）、SciPy（scp）、Scikit-Learn（sk）、PyTorch（py）和TensorFlow（tf）。")]),a._v(" "),e("h3",{attrs:{id:"评价指标"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#评价指标"}},[a._v("#")]),a._v(" 评价指标")]),a._v(" "),e("h4",{attrs:{id:"pass-k"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#pass-k"}},[a._v("#")]),a._v(" pass@k")]),a._v(" "),e("p",[a._v("代码的生成模型主要通过将样本与参考解决方案进行匹配来进行基准测试，其中匹配可以是精确的，也可以是模糊的（如BLEU分数）。然而，最近的工作却暴露了基于匹配的代码度量的不足。例如，BLEU在捕获特定于代码的语义特征方面存在问题，并建议对分数进行一些语义修改。")]),a._v(" "),e("p",[a._v("更根本的是，基于匹配的度量无法计算与参考解决方案功能等效的程序的大而复杂的空间。因此，最近在无监督代码翻译和伪代码到代码翻译方面的工作转向了功能正确性，"),e("strong",[a._v("即如果样本通过一组单元测试，则认为其是正确的。")])]),a._v(" "),e("p",[a._v("也许评估函数正确性最令人信服的原因是它被人类开发人员用来判断代码。一个被称为测试驱动开发dic的框架规定，在任何实现开始之前，软件需求都要转换为测试用例，而成功是由通过这些测试的程序来定义的。虽然很少有组织采用完全的测试驱动开发，但新代码的集成通常取决于创建和通过单元测试。")]),a._v(" "),e("p",[a._v("Kulal等人使用"),e("img",{staticStyle:{display:"inline-block",margin:"0"},attrs:{src:"https://math.now.sh?inline=pass%40k"}}),a._v("度量，其中每个问题生成k个代码样本，如果任何样本通过单元测试，则认为问题已解决，并报告已解决问题的总分数。然而，计算"),e("img",{staticStyle:{display:"inline-block",margin:"0"},attrs:{src:"https://math.now.sh?inline=pass%40k"}}),a._v("以这种方式可以具有高的方差。相反，要评估"),e("img",{staticStyle:{display:"inline-block",margin:"0"},attrs:{src:"https://math.now.sh?inline=pass%40k"}}),a._v("，我们每个任务生成n≥k个样本（在本文中，我们使用n=200和k≤100），计算通过单元测试的正确样本c≤n的数量，并计算无偏估计量：")]),a._v(" "),e("p",{},[e("img",{attrs:{src:"https://math.now.sh?from=%5Ctext%7Bpass%40%24k%24%7D%20%3A%3D%20%5Cmathop%7B%5Cmathbb%7BE%7D%7D_%7B%5Ctext%7BProblems%7D%7D%20%5Cleft%5B%201%20-%20%5Cfrac%7B%7B%5Cbinom%7Bn-c%7D%7Bk%7D%7D%7D%20%7B%5Cbinom%7Bn%7D%7Bk%7D%7D%20%5Cright%5D%0A"}})]),e("p",[a._v("计算这个估计量直接导致非常大的数量和数值不稳定性。下面包含了一个数字稳定的numpy实现，它简化了表达式并逐项计算乘积。")]),a._v(" "),e("div",{staticClass:"language-python line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("def")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[a._v("pass_at_k")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" c"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" k"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n    "),e("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[a._v('"""\n        :param n: total number of samples\n        :param c: number of correct samples\n        :param k: k in pass@k\n    """')]),a._v("\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("if")]),a._v(" n "),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),a._v(" c "),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v(" k"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v(" \n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0")]),a._v("\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),a._v(" np"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("prod"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),a._v(" k "),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v(" np"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("arange"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("n "),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),a._v(" c "),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" n "),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])]),a._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[a._v("1")]),e("br"),e("span",{staticClass:"line-number"},[a._v("2")]),e("br"),e("span",{staticClass:"line-number"},[a._v("3")]),e("br"),e("span",{staticClass:"line-number"},[a._v("4")]),e("br"),e("span",{staticClass:"line-number"},[a._v("5")]),e("br"),e("span",{staticClass:"line-number"},[a._v("6")]),e("br"),e("span",{staticClass:"line-number"},[a._v("7")]),e("br"),e("span",{staticClass:"line-number"},[a._v("8")]),e("br"),e("span",{staticClass:"line-number"},[a._v("9")]),e("br")])])])}),[],!1,null,null,null);t.default=r.exports}}]);
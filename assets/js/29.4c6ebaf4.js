(window.webpackJsonp=window.webpackJsonp||[]).push([[29],{752:function(r,a,t){"use strict";t.r(a);var o=t(1),e=Object(o.a)({},(function(){var r=this,a=r.$createElement,t=r._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":r.$parent.slotKey}},[t("h1",{attrs:{id:"å¤šæ¨¡æ€"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#å¤šæ¨¡æ€"}},[r._v("#")]),r._v(" å¤šæ¨¡æ€")]),r._v(" "),t("h2",{attrs:{id:"å¤šæ¨¡æ€æ¨ç†"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#å¤šæ¨¡æ€æ¨ç†"}},[r._v("#")]),r._v(" å¤šæ¨¡æ€æ¨ç†")]),r._v(" "),t("h3",{attrs:{id:"ç›¸å…³å·¥ä½œè°ƒç ”"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ç›¸å…³å·¥ä½œè°ƒç ”"}},[r._v("#")]),r._v(" ç›¸å…³å·¥ä½œè°ƒç ”")]),r._v(" "),t("ol",[t("li",[t("p",[t("strong",[r._v("Learn to Explain")]),r._v(" "),t("code",[r._v("(NIPS-22)")])]),r._v(" "),t("p",[t("a",{attrs:{href:"https://arxiv.org/abs/2209.09513",target:"_blank",rel:"noopener noreferrer"}},[r._v("[2209.09513] Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering (arxiv.org)"),t("OutboundLink")],1)]),r._v(" "),t("p",[r._v("æå‡ºå¤šæ¨¡æ€æ¨ç†æ•°æ®é›†")])]),r._v(" "),t("li",[t("p",[t("strong",[r._v("Multimodal-CoT")])]),r._v(" "),t("p",[t("a",{attrs:{href:"https://arxiv.org/abs/2302.00923",target:"_blank",rel:"noopener noreferrer"}},[r._v("[2302.00923] Multimodal Chain-of-Thought Reasoning in Language Models (arxiv.org)"),t("OutboundLink")],1)]),r._v(" "),t("p",[r._v("é¦–å…ˆå¯¹å¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œå¾®è°ƒä»¥ç”Ÿæˆæ€æƒ³é“¾ï¼Œç„¶åå¯¹ç†æ€§è¿›è¡Œæ¨ç†ä»¥è·å¾—æœ€ç»ˆç­”æ¡ˆã€‚ç„¶è€Œï¼Œå®ƒå—åˆ°æ¨ç†è¿‡ç¨‹çº¿æ€§çš„é™åˆ¶ï¼Œå¹¶ä¸”åœ¨ä¸åŒæ¨¡æ€ä¹‹é—´çš„äº¤äº’æ–¹é¢å­˜åœ¨å›°éš¾ã€‚")])]),r._v(" "),t("li",[t("p",[t("strong",[r._v("TSciQ")])]),r._v(" "),t("p",[t("a",{attrs:{href:"https://arxiv.org/abs/2305.03453",target:"_blank",rel:"noopener noreferrer"}},[r._v("[2305.03453] T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering (arxiv.org)"),t("OutboundLink")],1)]),r._v(" "),t("p",[r._v("é‡‡å–äº†"),t("strong",[r._v("åŸºäºçŸ¥è¯†æç‚¼")]),r._v("çš„æ–¹æ³•ã€‚TSciQä»LLMSç”Ÿæˆé«˜è´¨é‡çš„COTåŸç†ä½œä¸ºå¾®è°ƒä¿¡å·ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°çš„æ•°æ®æ··åˆç­–ç•¥æ¥ä¸ºä¸åŒçš„é—®é¢˜äº§ç”Ÿæœ‰æ•ˆçš„æ ·æœ¬ã€‚")])]),r._v(" "),t("li",[t("p",[t("strong",[r._v("Graph-of-Thought")])]),r._v(" "),t("p",[t("a",{attrs:{href:"https://arxiv.org/abs/2305.16582",target:"_blank",rel:"noopener noreferrer"}},[r._v("[2305.16582] Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models (arxiv.org)"),t("OutboundLink")],1)]),r._v(" "),t("p",[r._v("ä¸ºäº†ç¼“è§£å¤šæ¨¡å¼CoTé‡åˆ°çš„æŒ‘æˆ˜ï¼Œï¼ˆæå‡ºäº†æ€ç»´å›¾ï¼ˆGoTï¼‰ï¼Œå°†æ€ç»´è¿‡ç¨‹å»ºæ¨¡ä¸ºå›¾ã€‚å®ƒå°†æ¨ç†é“¾è§£æä¸º"),t("strong",[r._v("æ€ç»´å›¾")]),r._v("ï¼Œé€šè¿‡æ•æ‰éåºåˆ—ä¿¡æ¯äº¤äº’ï¼Œå¯ä»¥æ›´çœŸå®åœ°è¡¨ç¤ºæ€ç»´è¿‡ç¨‹ã€‚è¯¥æªæ–½é€šè¿‡å›¾å½¢ç»“æ„æ‰“ç ´äº†çº¿æ€§ç»“æ„çš„å±€é™æ€§ï¼Œè¿›ä¸€æ­¥æé«˜äº†æ€§èƒ½ã€‚")])]),r._v(" "),t("li",[t("p",[t("strong",[r._v("VCoT")])]),r._v(" "),t("p",[t("a",{attrs:{href:"https://arxiv.org/abs/2305.02317",target:"_blank",rel:"noopener noreferrer"}},[r._v("[2305.02317] Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings (arxiv.org)"),t("OutboundLink")],1)])]),r._v(" "),t("li",[t("p",[t("strong",[r._v("HoT")]),r._v("ğŸš¶â€â™‚ï¸")]),r._v(" "),t("p",[t("a",{attrs:{href:"https://arxiv.org/abs/2308.06207",target:"_blank",rel:"noopener noreferrer"}},[r._v("[2308.06207] Thinking Like an Expert:Multimodal Hypergraph-of-Thought (HoT) Reasoning to boost Foundation Modals (arxiv.org)"),t("OutboundLink")],1)]),r._v(" "),t("p",[r._v("æå‡ºäº†æ€ç»´è¶…å›¾ï¼ˆHoTï¼‰ï¼Œç”¨è¶…å›¾ä»£æ›¿æ€ç»´å›¾ï¼Œä½¿æ¨¡å‹å…·æœ‰æ›´å¥½çš„é«˜é˜¶å¤šè·³æ¨ç†å’Œå¤šæ¨¡æ€æ¯”è¾ƒåˆ¤æ–­èƒ½åŠ›ã€‚")])]),r._v(" "),t("li",[t("p",[t("strong",[r._v("DDCoT")]),r._v(" (NIPS-23)")]),r._v(" "),t("p",[t("a",{attrs:{href:"https://arxiv.org/abs/2310.16436",target:"_blank",rel:"noopener noreferrer"}},[r._v("[2310.16436] DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models (arxiv.org)"),t("OutboundLink")],1)])]),r._v(" "),t("li",[t("p",[t("strong",[r._v("MaTCR")]),r._v(" "),t("code",[r._v("(MM-23)")])]),r._v(" "),t("p",[t("a",{attrs:{href:"https://dlnext.acm.org/doi/pdf/10.1145/3581783.3612268",target:"_blank",rel:"noopener noreferrer"}},[r._v("MaTCR: Modality-Aligned Thought Chain Reasoning for Multimodal Task-Oriented Dialogue Generation (acm.org)"),t("OutboundLink")],1)])]),r._v(" "),t("li",[t("p",[t("strong",[r._v("ToMT")])]),r._v(" "),t("p",[t("a",{attrs:{href:"https://arxiv.org/abs/2308.09658",target:"_blank",rel:"noopener noreferrer"}},[r._v("[2308.09658] Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop Visual Reasoning (arxiv.org)"),t("OutboundLink")],1)]),r._v(" "),t("p",[r._v("åˆ©ç”¨æ€ç»´é“¾è¿›è¡Œè§†é¢‘æ¨ç†ä»ç„¶æ˜¯ä¸€ä¸ªæœªå¼€å‘çš„é¢†åŸŸï¼Œåªæœ‰å°‘æ•°ç ”ç©¶ã€‚CoMTè§†é¢‘æ¨ç†ä¸­çš„å¿«é€Ÿæ€ç»´å’Œæ…¢é€Ÿæ€ç»´ç›¸ç»“åˆï¼Œå¼•å…¥äº†ä¸€ç§ç”¨äºè§„åˆ’çš„æ ‘æœç´¢ç­–ç•¥ï¼Œ"),t("strong",[r._v("é¦–æ¬¡å°†CoTåº”ç”¨äºè§†é¢‘å¤šæ¨¡æ€æ¨ç†")]),r._v("ã€‚è™½ç„¶ä¸€äº›å·¥ä½œå·²ç»å¼€å§‹åˆ©ç”¨æ€ç»´é“¾æ¨ç†å’Œè§£å†³å¤šæ¨¡æ€æ¨ç†ä»»åŠ¡ï¼Œä½†ä»¥å‰çš„å·¥ä½œåªå…³æ³¨å¦‚ä½•æ„å»ºé«˜è´¨é‡çš„å¾®è°ƒæ•°æ®ï¼Œä»ç„¶å­˜åœ¨ä¸€äº›æŒ‘æˆ˜")])]),r._v(" "),t("li")]),r._v(" "),t("h3",{attrs:{id:"æ•°æ®é›†"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#æ•°æ®é›†"}},[r._v("#")]),r._v(" æ•°æ®é›†")]),r._v(" "),t("h4",{attrs:{id:"scienceqa"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#scienceqa"}},[r._v("#")]),r._v(" ScienceQA")]),r._v(" "),t("p",[r._v("ScienceQAæ˜¯ç¬¬ä¸€ä¸ª"),t("strong",[r._v("å¤§è§„æ¨¡å¤šæ¨¡æ€ç§‘å­¦é—®é¢˜æ•°æ®é›†")]),r._v("ï¼Œç”¨è¯¦ç»†çš„è®²åº§å’Œè§£é‡Šæ³¨é‡Šç­”æ¡ˆã€‚å®ƒåŒ…å«21kä¸ªå¤šæ¨¡æ€"),t("strong",[r._v("é€‰æ‹©é¢˜")]),r._v("ï¼Œå…·æœ‰ä¸°å¯Œçš„é¢†åŸŸå¤šæ ·æ€§ï¼Œæ¶µç›–3ä¸ªä¸»é¢˜ã€26ä¸ªä¸»é¢˜ã€127ä¸ªç±»åˆ«å’Œ379é¡¹æŠ€èƒ½ã€‚åŸºå‡†æ•°æ®é›†åˆ†ä¸ºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•ä¸‰éƒ¨åˆ†ï¼Œåˆ†åˆ«åŒ…å«12726ã€4241å’Œ4241ä¸ªç¤ºä¾‹ã€‚")])])}),[],!1,null,null,null);a.default=e.exports}}]);